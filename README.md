<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->
<a id="readme-top"></a>

<!-- PROJECT LOGO -->
<br />
<div align="center">
  <a href="https://github.com/shalvamist/OllamaRAG/">
  </a>
  <h1 align="center">ğŸ¦™ğŸ¦œğŸ”—OllamaRAGğŸ”—ğŸ¦œğŸ¦™</h1>
  <p align="center">
    An awesome Streamlit app to empower your Ollama RAG usage
  </p>
</div>

<!-- ABOUT THE PROJECT -->
## About The Project
OllamaRAG is a Streamlit app leveraging Ollama for local RAG applications

I am working enabling custom langchain RAG pipes but that work is TBD - at the moment only a simple RAG pipeline is supported 

### Built With  
[Langchain](https://github.com/langchain-ai/langchain)

[Ollama](https://github.com/ollama/ollama)

[Chroma](https://github.com/chroma-core/chroma)

> [!IMPORTANT - Requirments]
> 
> You will need Ollama running on your machine - you can find the installation steps here [Ollama download](https://ollama.com/download)
> Check out the colab link - Installation and run steps are detailed here ğŸ‘‡

## Colab
[ğŸ’¡ Google Colab Notebook](https://github.com/shalvamist/OllamaRAG/blob/main/OllamaRAG.ipynb)

## Installation
1. Clone the repo
   
   ```bash git clone https://github.com/shalvamist/OllamaRAG.git```
3. Install requirments

   ```bash pip install -r OllamaRAG/requirments.txt```
5. Run the Streamlit app
  
   ```bash streamlit run .\webApp.py```
