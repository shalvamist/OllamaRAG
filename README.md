<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->
<a id="readme-top"></a>

<!-- PROJECT LOGO -->
<br />
<div align="center">
  <a href="https://github.com/shalvamist/OllamaRAG/">
  </a>
  <h1 align="center">ðŸ¦™ðŸ¦œðŸ”—OllamaRAGðŸ”—ðŸ¦œðŸ¦™</h1>
  <p align="center">
    An awesome Streamlit app to empower your Ollama RAG usage
  </p>
</div>

<!-- ABOUT THE PROJECT -->
## About The Project
OllamaRAG is a Streamlit app leveraging Ollama for local RAG applications

I am working enabling custom langchain RAG pipes but that work is TBD - at the moment only a simple RAG pipeline is supported 

### Built With  
[Langchain](https://github.com/langchain-ai/langchain)

[Ollama](https://github.com/ollama/ollama)

[Chroma](https://github.com/chroma-core/chroma)

> [!IMPORTANT - Requirments]
> You will need Ollama running on your machine - you can find the installation steps here [Ollama download](https://ollama.com/download)

## Colab
[ðŸ’¡ Google Colab Notebook](https://github.com/shalvamist/OllamaRAG/blob/main/OllamaRAG.ipynb)

## Installation
1. Clone the repo
2. Install requirments
3. Run the Streamlit app - 'streamlit run .\webApp.py'
